Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xll4B1qU3G-JCiClQkqgrnqmeCPnYGam
"""

import pandas as pd
import sklearn
from sklearn.datasets import load_iris
from sklearn import preprocessing as pre
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
import json 
from collections import defaultdict
from collections import ChainMap
mlp_filename = "/content/ml_process.json"

# creating Initial value
#init value for preprocessing JSON
init_mlp_dict = {"Preprocessing":[],"MLA":[]}
with open(mlp_filename, 'w') as json_file:
  json.dump(init_mlp_dict, json_file, indent=2)

#accessing dict files from JSON
#for Preprocessing Method JSON
newdata={}
with open (mlp_filename) as access_json:
  read_content = json.load(access_json)

#for MLA JSON
with open (mlp_filename) as access_mla_json:
  read_mla_content = json.load(access_mla_json)


#method to parse SimpleImputer to JSON

def simpleImputerJSON():
  preprocessing_info = {"p_name":p_name, 
                          "p_parameter":[{"strategy":strategy}]}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename, "w") as f:
      sample = json.dump(read_content, f, indent=2)



#method to parse MinMaxScaler to JSON
def minMaxScaler():
  preprocessing_info = {"p_name":p_name, 
                          "p_parameter":[{"range":range}]}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename , "w") as f:
      json.dump(read_content, f, indent=2)

#method to parse MLA to JSON
#method for KNN
def knn():
  mla_info = {"mla_name":mla_name,
                "mla_parameter": [{"k_value":value}]}
  read_content['MLA'].append(mla_info)
  with open(mlp_filename, "w") as f:
      json.dump(read_content, f, indent=2)

#method for RandomForest
def randomForest():
  mla_info = {"mla_name":mla_name,
                "mla_parameter": [{"estimator": estimator, 
                                   "max_depth": max_depth}]}
  read_content['MLA'].append(mla_info)
  with open(mlp_filename, "w") as f:
      json.dump(read_content, f, indent=2)

#method for AdaBoostRegressor
def adaBoostRegressor():
  mla_info = {"mla_name":mla_name,
                "mla_parameter": [{"n_estimator": abr_n_estimator, 
                                   "loss": abr_loss}]}
  read_content['MLA'].append(mla_info)
  with open(mlp_filename, "w") as f:
      json.dump(read_content, f, indent=2)

#@title Preprocessing Option
pp_StandardScaler = True #@param {type:"boolean"}
pp_Normalizer = True #@param {type:"boolean"}
pp_SimpleImputer = True #@param {type:"boolean"}
si_strategy = "most_frequent" #@param ["mean", "median", "most_frequent", "constant"]
pp_MinMaxScaler = True #@param {type:"boolean"}
mms_range =  20#@param {type:"raw"}
pp_Binarization = True #@param {type:"boolean"}
bin_threshold =  1#@param {type:"raw"}

#@title Feature Selection
pp_VarianceThreshold = True #@param {type:"boolean"}
vt_threshold =  50#@param {type:"raw"}
pp_SelectKBest = True #@param {type:"boolean"}
skb_k_feat = 20#@param {type:"raw"}

if pp_StandardScaler == True:
  preprocessing_info = {"p_name":"StandardScaler"}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename , "w") as f:
      json.dump(read_content, f, indent=2)

if pp_Normalizer == True:
  preprocessing_info = {"p_name":"Normalizer"}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename , "w") as f:
      json.dump(read_content, f, indent=2)

if pp_SimpleImputer == True:
  ppName1 = "SimpleImputer"
  strategy = si_strategy
  p_name = ppName1
  simpleImputerJSON()

if pp_MinMaxScaler == True:
  ppName = "MinMaxScaler"
  p_name = ppName
  range = mms_range
  minMaxScaler()

if pp_Binarization == True:
  preprocessing_info = {"p_name":"Binarization", "p_parameter":[{"threshold": bin_threshold}]}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename , "w") as f:
      json.dump(read_content, f, indent=2)

if pp_VarianceThreshold == True:
  preprocessing_info = {"p_name":"Binarization", "p_parameter":[{"threshold": vt_threshold}]}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename , "w") as f:
      json.dump(read_content, f, indent=2)

if pp_SelectKBest == True:
  preprocessing_info = {"p_name":"SelectKBest", "p_parameter":[{"k": skb_k_feat}]}
  read_content['Preprocessing'].append(preprocessing_info)
  with open(mlp_filename , "w") as f:
      json.dump(read_content, f, indent=2)

#@title Machine Learning Algorithm Option
mla_KNN = True #@param {type:"boolean"}
knn_k_value = "" #@param {type:"string"}
mla_RandomForest = True #@param {type:"boolean"}
rf_n_estimators =  2#@param {type:"raw"}
rf_max_depth =  2#@param {type:"raw"}
mla_AdaBoostRegressor = True #@param {type:"boolean"}
abr_n_estimators = 2#@param {type:"raw"}
abr_loss = "linear" #@param ["linear", "square", "exponential"]

if mla_KNN == True:
  mla_name = "KNN"
  value = knn_k_value
  knn()

if mla_RandomForest == True:
  mla_name = "RandomForest"
  estimator = rf_n_estimators
  max_depth = rf_max_depth
  randomForest()

if mla_AdaBoostRegressor == True:
  mla_name = "AdaBoostRegressor"
  abr_n_estimator = abr_n_estimators
  abr_loss = abr_loss
  adaBoostRegressor()
